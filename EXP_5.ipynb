{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sara300804/BDT/blob/main/EXP_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uDV8WQmrYUmg"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz\n",
        "!tar -xzf pig-0.17.0.tar.gz\n",
        "!mv pig-0.17.0 /usr/local/pig\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"PIG_HOME\"] = \"/usr/local/pig\"\n",
        "os.environ[\"PATH\"] += \":/usr/local/pig/bin\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-y_zeGtY0aj",
        "outputId": "f8e3f9ab-c9f2-40c4-ca9a-960094b860c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,Arunachalam,IT,35000\n",
            "2,Balamurugan,HR,28000\n",
            "3,Kiran bedi,IT,42000\n",
            "4,Saravanan,Finance,39000\n",
            "5,Devi priya,HR,31000\n",
            "6,Ram dhanushkar,Finance,45000\n"
          ]
        }
      ],
      "source": [
        "data = \"\"\"1,Arunachalam,IT,35000\n",
        "2,Balamurugan,HR,28000\n",
        "3,Kiran bedi,IT,42000\n",
        "4,Saravanan,Finance,39000\n",
        "5,Devi priya,HR,31000\n",
        "6,Ram dhanushkar,Finance,45000\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/employee.txt\", \"w\") as f:\n",
        "    f.write(data)\n",
        "\n",
        "!cat /content/employee.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhRR5pAqY6pv",
        "outputId": "53da48fa-665d-43e7-a3b4-771a256228b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/usr/local/pig/lib/hadoop2-runtime/hadoop-auth-2.7.3.jar) to method sun.security.krb5.Config.getInstance()\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "2025-11-14 18:03:10,521 INFO  [main] pig.ExecTypeProvider (ExecTypeProvider.java:selectExecType(41)) - Trying ExecType : LOCAL\n",
            "2025-11-14 18:03:10,523 INFO  [main] pig.ExecTypeProvider (ExecTypeProvider.java:selectExecType(43)) - Picked LOCAL as the ExecType\n",
            "2025-11-14 18:03:10,566 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
            "2025-11-14 18:03:10,566 [main] INFO  org.apache.pig.Main - Logging error messages to: /content/pig_1763143390561.log\n",
            "2025-11-14 18:03:10,582 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2025-11-14 18:03:10,942 [main] ERROR org.apache.pig.Main - ERROR 2997: Encountered IOException. File /content/experiment5.pig does not exist\n",
            "Details at logfile: /content/pig_1763143390561.log\n",
            "2025-11-14 18:03:10,961 [main] INFO  org.apache.pig.Main - Pig script completed in 941 milliseconds (941 ms)\n"
          ]
        }
      ],
      "source": [
        "!pig -x local /content/experiment5.pig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZrmbehkahT2",
        "outputId": "28d72b4f-ec47-411c-aab1-2ac266ecb559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/experiment5.pig\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/experiment5.pig\n",
        "emp_data = LOAD '/content/employee.txt' USING PigStorage(',')\n",
        "            AS (id:int, name:chararray, dept:chararray, salary:int);\n",
        "\n",
        "grouped = GROUP emp_data BY dept;\n",
        "avg_salary = FOREACH grouped GENERATE group, AVG(emp_data.salary);\n",
        "\n",
        "STORE avg_salary INTO '/content/output_pig' USING PigStorage(',');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ1sUV1RY_ti",
        "outputId": "893230e6-65a3-4ca6-856c-0cae1638fc9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/usr/local/pig/lib/hadoop2-runtime/hadoop-auth-2.7.3.jar) to method sun.security.krb5.Config.getInstance()\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "2025-11-14 18:03:12,052 INFO  [main] pig.ExecTypeProvider (ExecTypeProvider.java:selectExecType(41)) - Trying ExecType : LOCAL\n",
            "2025-11-14 18:03:12,054 INFO  [main] pig.ExecTypeProvider (ExecTypeProvider.java:selectExecType(43)) - Picked LOCAL as the ExecType\n",
            "2025-11-14 18:03:12,100 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
            "2025-11-14 18:03:12,100 [main] INFO  org.apache.pig.Main - Logging error messages to: /content/pig_1763143392095.log\n",
            "2025-11-14 18:03:12,114 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2025-11-14 18:03:12,494 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
            "2025-11-14 18:03:12,679 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 18:03:12,681 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
            "2025-11-14 18:03:12,702 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-experiment5.pig-5f5e2853-d11c-478c-9a5f-964f7c39f73a\n",
            "2025-11-14 18:03:12,702 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
            "2025-11-14 18:03:13,098 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
            "2025-11-14 18:03:13,119 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY\n",
            "2025-11-14 18:03:13,176 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
            "2025-11-14 18:03:13,223 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 18:03:13,265 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
            "2025-11-14 18:03:13,276 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
            "2025-11-14 18:03:13,297 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 1\n",
            "2025-11-14 18:03:13,297 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 1\n",
            "2025-11-14 18:03:13,356 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2025-11-14 18:03:13,356 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2025-11-14 18:03:13,384 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
            "2025-11-14 18:03:13,394 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 18:03:13,394 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
            "2025-11-14 18:03:13,398 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
            "2025-11-14 18:03:13,400 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
            "2025-11-14 18:03:13,401 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
            "2025-11-14 18:03:13,405 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=147\n",
            "2025-11-14 18:03:13,405 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
            "2025-11-14 18:03:13,406 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 18:03:13,420 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
            "2025-11-14 18:03:13,426 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
            "2025-11-14 18:03:13,426 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
            "2025-11-14 18:03:13,426 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1763143393425-0\n",
            "2025-11-14 18:03:13,532 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
            "2025-11-14 18:03:13,533 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
            "2025-11-14 18:03:13,543 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:13,566 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2025-11-14 18:03:13,583 [JobControl] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "2025-11-14 18:03:13,647 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
            "2025-11-14 18:03:13,658 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 18:03:13,661 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
            "2025-11-14 18:03:13,662 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
            "2025-11-14 18:03:13,694 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
            "2025-11-14 18:03:13,762 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
            "2025-11-14 18:03:13,959 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1250057205_0001\n",
            "2025-11-14 18:03:14,110 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
            "2025-11-14 18:03:14,110 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1250057205_0001\n",
            "2025-11-14 18:03:14,110 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases avg_salary,emp_data,grouped\n",
            "2025-11-14 18:03:14,111 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: emp_data[1,11],emp_data[-1,-1],avg_salary[5,13],grouped[4,10] C: avg_salary[5,13],grouped[4,10] R: avg_salary[5,13]\n",
            "2025-11-14 18:03:14,120 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
            "2025-11-14 18:03:14,120 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1250057205_0001]\n",
            "2025-11-14 18:03:14,120 [Thread-18] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
            "2025-11-14 18:03:14,144 [Thread-18] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
            "2025-11-14 18:03:14,145 [Thread-18] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2025-11-14 18:03:14,145 [Thread-18] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
            "2025-11-14 18:03:14,146 [Thread-18] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
            "2025-11-14 18:03:14,147 [Thread-18] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 18:03:14,148 [Thread-18] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
            "2025-11-14 18:03:14,187 [Thread-18] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
            "2025-11-14 18:03:14,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1250057205_0001_m_000000_0\n",
            "2025-11-14 18:03:14,225 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 18:03:14,246 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 18:03:14,255 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
            "Total Length = 147\n",
            "Input split[0]:\n",
            "   Length = 147\n",
            "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
            "   Locations:\n",
            "\n",
            "-----------------------\n",
            "\n",
            "2025-11-14 18:03:14,268 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
            "2025-11-14 18:03:14,271 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/employee.txt:0+147\n",
            "2025-11-14 18:03:14,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2025-11-14 18:03:14,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
            "2025-11-14 18:03:14,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
            "2025-11-14 18:03:14,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
            "2025-11-14 18:03:14,347 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
            "2025-11-14 18:03:14,354 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2025-11-14 18:03:14,362 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 18:03:14,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
            "2025-11-14 18:03:14,393 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: emp_data[1,11],emp_data[-1,-1],avg_salary[5,13],grouped[4,10] C: avg_salary[5,13],grouped[4,10] R: avg_salary[5,13]\n",
            "2025-11-14 18:03:14,404 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
            "2025-11-14 18:03:14,404 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
            "2025-11-14 18:03:14,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
            "2025-11-14 18:03:14,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 96; bufvoid = 104857600\n",
            "2025-11-14 18:03:14,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600\n",
            "2025-11-14 18:03:14,445 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: emp_data[1,11],emp_data[-1,-1],avg_salary[5,13],grouped[4,10] C: avg_salary[5,13],grouped[4,10] R: avg_salary[5,13]\n",
            "2025-11-14 18:03:14,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
            "2025-11-14 18:03:14,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1250057205_0001_m_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 18:03:14,463 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
            "2025-11-14 18:03:14,463 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1250057205_0001_m_000000_0' done.\n",
            "2025-11-14 18:03:14,463 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1250057205_0001_m_000000_0\n",
            "2025-11-14 18:03:14,464 [Thread-18] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
            "2025-11-14 18:03:14,466 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1250057205_0001_r_000000_0\n",
            "2025-11-14 18:03:14,466 [Thread-18] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
            "2025-11-14 18:03:14,492 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 18:03:14,496 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
            "2025-11-14 18:03:14,498 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3c0cb5fa\n",
            "2025-11-14 18:03:14,509 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2025-11-14 18:03:14,512 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1250057205_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2025-11-14 18:03:14,575 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1250057205_0001_m_000000_0 decomp: 61 len: 65 to MEMORY\n",
            "2025-11-14 18:03:14,578 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 61 bytes from map-output for attempt_local1250057205_0001_m_000000_0\n",
            "2025-11-14 18:03:14,579 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 61, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->61\n",
            "2025-11-14 18:03:14,582 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
            "2025-11-14 18:03:14,584 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 18:03:14,584 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2025-11-14 18:03:14,590 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 18:03:14,590 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 54 bytes\n",
            "2025-11-14 18:03:14,591 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 61 bytes to disk to satisfy reduce memory limit\n",
            "2025-11-14 18:03:14,592 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 65 bytes from disk\n",
            "2025-11-14 18:03:14,592 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
            "2025-11-14 18:03:14,593 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
            "2025-11-14 18:03:14,593 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 54 bytes\n",
            "2025-11-14 18:03:14,593 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 18:03:14,599 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
            "2025-11-14 18:03:14,612 [pool-3-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2025-11-14 18:03:14,613 [pool-3-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n",
            "2025-11-14 18:03:14,613 [pool-3-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
            "2025-11-14 18:03:14,622 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
            "2025-11-14 18:03:14,622 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1250057205_0001]\n",
            "2025-11-14 18:03:14,624 [pool-3-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: emp_data[1,11],emp_data[-1,-1],avg_salary[5,13],grouped[4,10] C: avg_salary[5,13],grouped[4,10] R: avg_salary[5,13]\n",
            "2025-11-14 18:03:14,631 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1250057205_0001_r_000000_0 is done. And is in the process of committing\n",
            "2025-11-14 18:03:14,638 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
            "2025-11-14 18:03:14,638 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1250057205_0001_r_000000_0 is allowed to commit now\n",
            "2025-11-14 18:03:14,643 [pool-3-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1250057205_0001_r_000000_0' to file:/content/output_pig/_temporary/0/task_local1250057205_0001_r_000000\n",
            "2025-11-14 18:03:14,646 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
            "2025-11-14 18:03:14,647 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1250057205_0001_r_000000_0' done.\n",
            "2025-11-14 18:03:14,647 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1250057205_0001_r_000000_0\n",
            "2025-11-14 18:03:14,647 [Thread-18] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
            "2025-11-14 18:03:14,863 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:14,871 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:14,871 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2025-11-14 18:03:14,872 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:14,914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
            "2025-11-14 18:03:14,918 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
            "\n",
            "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
            "2.7.3\t0.17.0\troot\t2025-11-14 18:03:13\t2025-11-14 18:03:14\tGROUP_BY\n",
            "\n",
            "Success!\n",
            "\n",
            "Job Stats (time in seconds):\n",
            "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
            "job_local1250057205_0001\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tavg_salary,emp_data,grouped\tGROUP_BY,COMBINER\t/content/output_pig,\n",
            "\n",
            "Input(s):\n",
            "Successfully read 6 records from: \"/content/employee.txt\"\n",
            "\n",
            "Output(s):\n",
            "Successfully stored 3 records in: \"/content/output_pig\"\n",
            "\n",
            "Counters:\n",
            "Total records written : 3\n",
            "Total bytes written : 0\n",
            "Spillable Memory Manager spill count : 0\n",
            "Total bags proactively spilled: 0\n",
            "Total records proactively spilled: 0\n",
            "\n",
            "Job DAG:\n",
            "job_local1250057205_0001\n",
            "\n",
            "\n",
            "2025-11-14 18:03:14,921 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:14,928 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:14,929 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
            "2025-11-14 18:03:14,943 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
            "2025-11-14 18:03:14,977 [main] INFO  org.apache.pig.Main - Pig script completed in 3 seconds and 379 milliseconds (3379 ms)\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/output_pig\n",
        "!pig -x local /content/experiment5.pig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbSAjFkLZGsU",
        "outputId": "ce59fc2b-89d4-47c8-8460-f971e5ce027e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HR,29500.0\n",
            "IT,38500.0\n",
            "Finance,42000.0\n"
          ]
        }
      ],
      "source": [
        "!cat /content/output_pig/part-r-00000\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}